# -*- coding: utf-8 -*-
"""Copy of Meta_Model_Training_Imp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hEFEVJHmI3IPuWTqtRnUlP_rN7rtZQMr
"""

from google.colab import files  # Import the files module

uploaded = files.upload()  # Opens a file picker

"""We compute the **Pearson correlation** between each feature and `Next_Day_Return` to identify the most linearly predictive variables.  
This helps us select the **top 20 features** for modeling by filtering out low-signal inputs.
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns

# Load CSV
df = pd.read_csv("META_FeatureMart_2020_2024_FULL.csv", parse_dates=["Date"])

# Set index to Date if needed
df.set_index("Date", inplace=True)

# Define target
target = "Next_Day_Return"

# Drop rows where target is missing
df = df[df[target].notna()]

# Fill missing values
df = df.bfill().ffill()

# Drop non-feature columns (customize based on modeling later)
non_feature_cols = [
    "Target_3D", "Target_7D", "Signal_Score", "Strong_Buy",
    "Buy_Signal", "Sell_Signal", "Volatility_Level", target
]
features = df.drop(columns=non_feature_cols, errors='ignore')

# Select only numeric features
X = features.select_dtypes(include=[np.number])

# Standardize features
scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns, index=X.index)

# Final target column
y = df[target]

# Feature correlation with target
correlation = X_scaled.corrwith(y).sort_values(ascending=False)

# Top features
top_features = correlation.abs().sort_values(ascending=False).head(20)

# Plot correlation
plt.figure(figsize=(10, 6))
sns.barplot(x=top_features.values, y=top_features.index)
plt.title("Top 20 Feature Correlations with Next_Day_Return")
plt.xlabel("Correlation")
plt.grid(True)
plt.tight_layout()
plt.show()

# Print selected features for modeling
print("Top features selected for modeling:\n", top_features.index.tolist())

import pandas as pd
import numpy as np
import statsmodels.api as sm
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns

# Load and preprocess data
df = pd.read_csv("META_FeatureMart_2020_2024_FULL.csv", parse_dates=["Date"])
df.set_index("Date", inplace=True)
target = "Next_Day_Return"
df = df[df[target].notna()].bfill().ffill()

# Drop non-feature columns
non_feature_cols = ["Target_3D", "Target_7D", "Signal_Score", "Strong_Buy", "Buy_Signal", "Sell_Signal", "Volatility_Level", target]
features = df.drop(columns=non_feature_cols, errors='ignore')
X = features.select_dtypes(include='number')

# Standardize
scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns, index=X.index)

# Define target
y = df[target]

# Run OLS with constant
X_const = sm.add_constant(X_scaled)
ols_model = sm.OLS(y, X_const).fit()
t_values = ols_model.tvalues

# Thresholding
threshold = 2
tvals_df = pd.DataFrame({'Feature': t_values.index, 't_stat': t_values.values}).set_index('Feature')
tvals_significant = tvals_df.drop(index='const', errors='ignore')
tvals_significant = tvals_significant[abs(tvals_significant['t_stat']) > threshold]
tvals_sorted = tvals_significant.sort_values(by='t_stat', key=abs, ascending=False)

# Plot
plt.figure(figsize=(10, 6))
sns.barplot(y=tvals_sorted.index, x=tvals_sorted['t_stat'], palette='coolwarm')
plt.axvline(x=threshold, color='green', linestyle='--', label='|t| = 2')
plt.axvline(x=-threshold, color='green', linestyle='--')
plt.title("ğŸ“Š Significant Features from Hard Thresholding (|t-stat| > 2)")
plt.xlabel("t-statistic")
plt.ylabel("Feature")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# Display final features
print("Selected Features:\n", tvals_sorted)

# ğŸ“Œ Install necessary packages (if not already installed)
!pip install --quiet statsmodels seaborn

# ğŸ“Œ Step 1: Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
import statsmodels.api as sm

# ğŸ“Œ Step 2: Load the data
df = pd.read_csv("META_FeatureMart_2020_2024_FULL.csv", parse_dates=["Date"])
df.set_index("Date", inplace=True)

# ğŸ“Œ Step 3: Preprocessing
target = "Next_Day_Return"
df = df[df[target].notna()]
df = df.bfill().ffill()

# Drop columns that shouldn't be used as features
non_feature_cols = [
    "Target_3D", "Target_7D", "Signal_Score", "Strong_Buy",
    "Buy_Signal", "Sell_Signal", "Volatility_Level", target
]
X = df.drop(columns=non_feature_cols, errors='ignore').select_dtypes(include='number')
y = df[target]

# ğŸ“Œ Step 4: Standardize features
scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns, index=X.index)

# ğŸ“Œ Step 5: Run OLS on all features
X_with_const = sm.add_constant(X_scaled)
ols_model = sm.OLS(y, X_with_const).fit()

# ğŸ“Œ Step 6: Hard thresholding |t| â‰¥ 1.96
t_values = ols_model.tvalues
selected_features = t_values[abs(t_values) >= 1.96].index.tolist()
selected_features = [feat for feat in selected_features if feat != 'const']

# ğŸ“Œ Step 7: Refit model using selected features
X_selected = X_scaled[selected_features]
X_selected_const = sm.add_constant(X_selected)
final_model = sm.OLS(y, X_selected_const).fit()

# ğŸ“Œ Step 8: Plot all t-values
threshold = 1.0
filtered_tvals = t_values.drop("const")[abs(t_values.drop("const")) >= threshold]
plt.figure(figsize=(12, 6))
sns.barplot(x=filtered_tvals.values, y=filtered_tvals.index, palette="coolwarm")
plt.axvline(x=1.96, color='green', linestyle='--', label='|t| = 1.96 Threshold')
plt.axvline(x=-1.96, color='green', linestyle='--')
plt.title("Filtered T-Statistics (|t| â‰¥ 1.0)")
plt.xlabel("t-statistic")
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()

# ğŸ“Œ Step 9: Print regression summary
print(final_model.summary())

"""**Train-Test Split (Time-Aware)**

Split the data based on date:

Train: Jan 2020 â€“ Dec 2022
Test: Jan 2023 â€“ Dec 2024


"""

# Step 1: Time-aware train/test split

# Ensure index is datetime
X_scaled.index = pd.to_datetime(X_scaled.index)
y.index = pd.to_datetime(y.index)

# Define split dates
train_end = '2022-12-31'
test_start = '2023-01-01'

# Split features and target
X_train = X_scaled.loc[:train_end]
X_test = X_scaled.loc[test_start:]
y_train = y.loc[:train_end]
y_test = y.loc[test_start:]

print(f"âœ… Training set shape: {X_train.shape}, Testing set shape: {X_test.shape}")

"""OLS Baseline with Hard-Thresholded Features"""

from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# Step 2: Train OLS Baseline using selected features
selected_features = ['Return_3D', 'Mkt-RF', 'SMB', 'HML']

X_train_ols = sm.add_constant(X_train[selected_features])
X_test_ols = sm.add_constant(X_test[selected_features])

# Fit OLS
ols_model = sm.OLS(y_train, X_train_ols).fit()

# Predict
y_train_pred = ols_model.predict(X_train_ols)
y_test_pred = ols_model.predict(X_test_ols)

# Evaluation Metrics
# Compute RMSE manually
rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))
rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))

# RÂ² remains the same
r2_train = r2_score(y_train, y_train_pred)
r2_test = r2_score(y_test, y_test_pred)

# Initialize model results tracker (create once at top)
results = []

# After evaluating any model, log results like this:
results.append({
    'Model': 'OLS Baseline',
    'Train RMSE': rmse_train,
    'Test RMSE': rmse_test,
    'Train RÂ²': r2_train,
    'Test RÂ²': r2_test
})

# View results
results_df = pd.DataFrame(results)
display(results_df)

"""**Fama-French 3-Factor Model (FF3)**"""

import yfinance as yf
import numpy as np
import pandas as pd
import statsmodels.api as sm
from sklearn.metrics import mean_squared_error, r2_score

# Download META stock price
meta = yf.download("META", start="2020-01-01", end="2024-01-01")
meta = meta[['Close']].copy()
meta['log_return'] = np.log(meta['Close'] / meta['Close'].shift(1))

# Load your feature mart CSV
df = pd.read_csv("META_FeatureMart_2020_2024_FULL", parse_dates=['date'])
df.set_index('date', inplace=True)

# Merge with log return
meta.index = meta.index.tz_localize(None)
combined = df.merge(meta[['log_return']], left_index=True, right_index=True, how='inner')

# Create excess log return
combined['excess_log_return'] = combined['log_return'] - combined['RF']

# Lag FF3 factors
for col in ['Mkt-RF', 'SMB', 'HML']:
    combined[f'{col}_lag1'] = combined[col].shift(1)

# Prepare data
ff3_X = combined[['Mkt-RF_lag1', 'SMB_lag1', 'HML_lag1']].dropna()
ff3_y = combined['excess_log_return'].loc[ff3_X.index]

# Train-test split
X_train_ff3 = ff3_X.loc[:'2022-12-31']
X_test_ff3 = ff3_X.loc['2023-01-01':]
y_train_ff3 = ff3_y.loc[:'2022-12-31']
y_test_ff3 = ff3_y.loc['2023-01-01':]

# Add constant and fit model
X_train_const = sm.add_constant(X_train_ff3)
X_test_const = sm.add_constant(X_test_ff3)
model = sm.OLS(y_train_ff3, X_train_const).fit()

# Predict and evaluate
y_train_pred = model.predict(X_train_const)
y_test_pred = model.predict(X_test_const)
print(model.summary())

# Evaluation
rmse_train = np.sqrt(mean_squared_error(y_train_ff3, y_train_pred))
rmse_test = np.sqrt(mean_squared_error(y_test_ff3, y_test_pred))
r2_train = r2_score(y_train_ff3, y_train_pred)
r2_test = r2_score(y_test_ff3, y_test_pred)

print("\nğŸ” Evaluation Metrics:")
print(f"Train RMSE: {rmse_train:.6f}")
print(f"Test RMSE:  {rmse_test:.6f}")
print(f"Train RÂ²:   {r2_train:.4f}")
print(f"Test RÂ²:    {r2_test:.4f}")

"""AR(1) â€“ Autoregression with Lag 1"""

# Create lagged return feature (t-1)
df['Lag_1_Return'] = df['Next_Day_Return'].shift(1)

# Drop rows with NA due to shifting
ar_df = df[['Next_Day_Return', 'Lag_1_Return']].dropna()

# Split into train/test
X_ar = ar_df[['Lag_1_Return']]
y_ar = ar_df['Next_Day_Return']
X_train_ar = X_ar.loc[:'2022-12-31']
X_test_ar = X_ar.loc['2023-01-01':]
y_train_ar = y_ar.loc[:'2022-12-31']
y_test_ar = y_ar.loc['2023-01-01':]

# Fit OLS model
X_train_ar_const = sm.add_constant(X_train_ar)
X_test_ar_const = sm.add_constant(X_test_ar)
ar1_model = sm.OLS(y_train_ar, X_train_ar_const).fit()

# Predict
y_train_ar_pred = ar1_model.predict(X_train_ar_const)
y_test_ar_pred = ar1_model.predict(X_test_ar_const)

# Evaluate
rmse_train_ar = np.sqrt(mean_squared_error(y_train_ar, y_train_ar_pred))
rmse_test_ar = np.sqrt(mean_squared_error(y_test_ar, y_test_ar_pred))
r2_train_ar = r2_score(y_train_ar, y_train_ar_pred)
r2_test_ar = r2_score(y_test_ar, y_test_ar_pred)

# Log results
results.append({
    'Model': 'AR(1)',
    'Train RMSE': rmse_train_ar,
    'Test RMSE': rmse_test_ar,
    'Train RÂ²': r2_train_ar,
    'Test RÂ²': r2_test_ar
})

# View results table
results_df = pd.DataFrame(results)
display(results_df)

from sklearn.linear_model import ElasticNetCV
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler

# Use all standardized features (X_scaled) from earlier
# Align y index just in case
y = y.loc[X_scaled.index]

# Train-test split
X_train_en = X_scaled.loc[:'2022-12-31']
X_test_en = X_scaled.loc['2023-01-01':]
y_train_en = y.loc[:'2022-12-31']
y_test_en = y.loc['2023-01-01':]

# Clean up NaNs
X_train_en = X_train_en.dropna()
y_train_en = y_train_en.loc[X_train_en.index]

X_test_en = X_test_en.dropna()
y_test_en = y_test_en.loc[X_test_en.index]

# Fit model
model_en.fit(X_train_en, y_train_en)


# ElasticNet with cross-validation (for alpha and l1_ratio)
elastic_net = ElasticNetCV(cv=5, random_state=42, l1_ratio=[.1, .5, .7, .9, .95, .99, 1], max_iter=10000)
model_en = make_pipeline(StandardScaler(), elastic_net)  # in case features not scaled

# Fit model
model_en.fit(X_train_en, y_train_en)

# Predict
y_train_en_pred = model_en.predict(X_train_en)
y_test_en_pred = model_en.predict(X_test_en)

# Evaluate
rmse_train_en = np.sqrt(mean_squared_error(y_train_en, y_train_en_pred))
rmse_test_en = np.sqrt(mean_squared_error(y_test_en, y_test_en_pred))
r2_train_en = r2_score(y_train_en, y_train_en_pred)
r2_test_en = r2_score(y_test_en, y_test_en_pred)

# Log results
results.append({
    'Model': 'ElasticNet',
    'Train RMSE': rmse_train_en,
    'Test RMSE': rmse_test_en,
    'Train RÂ²': r2_train_en,
    'Test RÂ²': r2_test_en
})

# Display
results_df = pd.DataFrame(results)
display(results_df)

from sklearn.decomposition import PCA

# Drop NaNs before PCA
X_scaled_pca = X_scaled.dropna()
y = y.loc[X_scaled_pca.index]  # align target

# Apply PCA
pca = PCA(n_components=3)
X_pca = pd.DataFrame(pca.fit_transform(X_scaled_pca), index=X_scaled_pca.index, columns=['PC1', 'PC2', 'PC3'])

# Train-test split
X_train_pca = X_pca.loc[:'2022-12-31']
X_test_pca = X_pca.loc['2023-01-01':]
y_train_pca = y.loc[:'2022-12-31']
y_test_pca = y.loc['2023-01-01':]

# Fit OLS on PCs
X_train_pca_const = sm.add_constant(X_train_pca)
X_test_pca_const = sm.add_constant(X_test_pca)
pca_model = sm.OLS(y_train_pca, X_train_pca_const).fit()

# Predict
y_train_pca_pred = pca_model.predict(X_train_pca_const)
y_test_pca_pred = pca_model.predict(X_test_pca_const)

# Evaluate
rmse_train_pca = np.sqrt(mean_squared_error(y_train_pca, y_train_pca_pred))
rmse_test_pca = np.sqrt(mean_squared_error(y_test_pca, y_test_pca_pred))
r2_train_pca = r2_score(y_train_pca, y_train_pca_pred)
r2_test_pca = r2_score(y_test_pca, y_test_pca_pred)

# Log results
results.append({
    'Model': 'PCA + OLS',
    'Train RMSE': rmse_train_pca,
    'Test RMSE': rmse_test_pca,
    'Train RÂ²': r2_train_pca,
    'Test RÂ²': r2_test_pca
})

# View table
results_df = pd.DataFrame(results)
display(results_df)

# Create lagged features
df['Lag_1_Return'] = df['Next_Day_Return'].shift(1)
df['ADS_lag1'] = df['ADS_Index'].shift(1)

# Drop missing values from shifting
aug_df = df[['Next_Day_Return', 'Lag_1_Return', 'ADS_lag1']].dropna()

# Define X and y
X_aug = aug_df[['Lag_1_Return', 'ADS_lag1']]
y_aug = aug_df['Next_Day_Return']

# Time-based split
X_train_aug = X_aug.loc[:'2022-12-31']
X_test_aug = X_aug.loc['2023-01-01':]
y_train_aug = y_aug.loc[:'2022-12-31']
y_test_aug = y_aug.loc['2023-01-01':]

# Fit model
X_train_aug_const = sm.add_constant(X_train_aug)
X_test_aug_const = sm.add_constant(X_test_aug)
aug_model = sm.OLS(y_train_aug, X_train_aug_const).fit()

# Predict
y_train_aug_pred = aug_model.predict(X_train_aug_const)
y_test_aug_pred = aug_model.predict(X_test_aug_const)

# Evaluate
rmse_train_aug = np.sqrt(mean_squared_error(y_train_aug, y_train_aug_pred))
rmse_test_aug = np.sqrt(mean_squared_error(y_test_aug, y_test_aug_pred))
r2_train_aug = r2_score(y_train_aug, y_train_aug_pred)
r2_test_aug = r2_score(y_test_aug, y_test_aug_pred)

# Log results
results.append({
    'Model': 'Augmented AR(1) (with ADS)',
    'Train RMSE': rmse_train_aug,
    'Test RMSE': rmse_test_aug,
    'Train RÂ²': r2_train_aug,
    'Test RÂ²': r2_test_aug
})

# Display updated model comparison
results_df = pd.DataFrame(results)
display(results_df)

from sklearn.ensemble import RandomForestRegressor

# Drop rows with any remaining NaNs
X_rf = X_scaled.dropna()
y_rf = y.loc[X_rf.index]

# Train-test split
X_train_rf = X_rf.loc[:'2022-12-31']
X_test_rf = X_rf.loc['2023-01-01':]
y_train_rf = y_rf.loc[:'2022-12-31']
y_test_rf = y_rf.loc['2023-01-01':]

# Fit Random Forest
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train_rf, y_train_rf)

# Predict
y_train_rf_pred = rf_model.predict(X_train_rf)
y_test_rf_pred = rf_model.predict(X_test_rf)

# Evaluate
rmse_train_rf = np.sqrt(mean_squared_error(y_train_rf, y_train_rf_pred))
rmse_test_rf = np.sqrt(mean_squared_error(y_test_rf, y_test_rf_pred))
r2_train_rf = r2_score(y_train_rf, y_train_rf_pred)
r2_test_rf = r2_score(y_test_rf, y_test_rf_pred)

# Log results
results.append({
    'Model': 'Random Forest',
    'Train RMSE': rmse_train_rf,
    'Test RMSE': rmse_test_rf,
    'Train RÂ²': r2_train_rf,
    'Test RÂ²': r2_test_rf
})

# Display final results
results_df = pd.DataFrame(results)
display(results_df)

# Compute excess returns
df['META_excess'] = df['Next_Day_Return']
df['Mkt_excess'] = df['Mkt-RF']  # already excess return

# Align and drop NaNs
capm_df = df[['META_excess', 'Mkt_excess']].dropna()

rf = df['T10Y3M']
df['META_excess'] = df['Next_Day_Return'] - rf
df['Mkt_excess'] = df['Mkt-RF']  # already adjusted by rf

# Split
X_capm = capm_df[['Mkt_excess']]
y_capm = capm_df['META_excess']
X_train_capm = X_capm.loc[:'2022-12-31']
X_test_capm = X_capm.loc['2023-01-01':]
y_train_capm = y_capm.loc[:'2022-12-31']
y_test_capm = y_capm.loc['2023-01-01':]

# Fit OLS
X_train_capm_const = sm.add_constant(X_train_capm)
X_test_capm_const = sm.add_constant(X_test_capm)
capm_model = sm.OLS(y_train_capm, X_train_capm_const).fit()

# Predict
y_train_capm_pred = capm_model.predict(X_train_capm_const)
y_test_capm_pred = capm_model.predict(X_test_capm_const)

# Evaluate
rmse_train_capm = np.sqrt(mean_squared_error(y_train_capm, y_train_capm_pred))
rmse_test_capm = np.sqrt(mean_squared_error(y_test_capm, y_test_capm_pred))
r2_train_capm = r2_score(y_train_capm, y_train_capm_pred)
r2_test_capm = r2_score(y_test_capm, y_test_capm_pred)

results = [r for r in results if r['Model'] != 'CAPM']

# Log
results.append({
    'Model': 'CAPM',
    'Train RMSE': rmse_train_capm,
    'Test RMSE': rmse_test_capm,
    'Train RÂ²': r2_train_capm,
    'Test RÂ²': r2_test_capm
})

# Display final results
results_df = pd.DataFrame(results)
display(results_df)

from sklearn.linear_model import RidgeCV

# Ensure NaNs removed
X_ridge = X_scaled.dropna()
y_ridge = y.loc[X_ridge.index]

# Split
X_train_ridge = X_ridge.loc[:'2022-12-31']
X_test_ridge = X_ridge.loc['2023-01-01':]
y_train_ridge = y_ridge.loc[:'2022-12-31']
y_test_ridge = y_ridge.loc['2023-01-01':]

# Ridge with built-in cross-validation
ridge_model = RidgeCV(alphas=np.logspace(-4, 4, 50), cv=5)
ridge_model.fit(X_train_ridge, y_train_ridge)

# Predict
y_train_ridge_pred = ridge_model.predict(X_train_ridge)
y_test_ridge_pred = ridge_model.predict(X_test_ridge)

# Evaluate
rmse_train_ridge = np.sqrt(mean_squared_error(y_train_ridge, y_train_ridge_pred))
rmse_test_ridge = np.sqrt(mean_squared_error(y_test_ridge, y_test_ridge_pred))
r2_train_ridge = r2_score(y_train_ridge, y_train_ridge_pred)
r2_test_ridge = r2_score(y_test_ridge, y_test_ridge_pred)

# Log
results.append({
    'Model': 'Ridge Regression',
    'Train RMSE': rmse_train_ridge,
    'Test RMSE': rmse_test_ridge,
    'Train RÂ²': r2_train_ridge,
    'Test RÂ²': r2_test_ridge
})

# Display final results
results = [r for i, r in enumerate(results) if r['Model'] != 'Ridge Regression' or i == 6]  # Keep only 1st CAPM if needed
results_df = pd.DataFrame(results)
display(results_df)

from sklearn.linear_model import LassoCV

# Drop NaNs
X_lasso = X_scaled.dropna()
y_lasso = y.loc[X_lasso.index]

# Split
X_train_lasso = X_lasso.loc[:'2022-12-31']
X_test_lasso = X_lasso.loc['2023-01-01':]
y_train_lasso = y_lasso.loc[:'2022-12-31']
y_test_lasso = y_lasso.loc['2023-01-01':]

# Lasso with CV
lasso_model = LassoCV(cv=5, random_state=42, max_iter=10000)
lasso_model.fit(X_train_lasso, y_train_lasso)

# Predict
y_train_lasso_pred = lasso_model.predict(X_train_lasso)
y_test_lasso_pred = lasso_model.predict(X_test_lasso)

# Evaluate
rmse_train_lasso = np.sqrt(mean_squared_error(y_train_lasso, y_train_lasso_pred))
rmse_test_lasso = np.sqrt(mean_squared_error(y_test_lasso, y_test_lasso_pred))
r2_train_lasso = r2_score(y_train_lasso, y_train_lasso_pred)
r2_test_lasso = r2_score(y_test_lasso, y_test_lasso_pred)

# Log
results.append({
    'Model': 'Lasso Regression',
    'Train RMSE': rmse_train_lasso,
    'Test RMSE': rmse_test_lasso,
    'Train RÂ²': r2_train_lasso,
    'Test RÂ²': r2_test_lasso
})

results_df = pd.DataFrame(results)
display(results_df)

from sklearn.ensemble import GradientBoostingRegressor

# Drop NaNs
X_gb = X_scaled.dropna()
y_gb = y.loc[X_gb.index]

# Split
X_train_gb = X_gb.loc[:'2022-12-31']
X_test_gb = X_gb.loc['2023-01-01':]
y_train_gb = y_gb.loc[:'2022-12-31']
y_test_gb = y_gb.loc['2023-01-01':]

# Fit Gradient Boosting
gb_model = GradientBoostingRegressor(n_estimators=200, max_depth=4, learning_rate=0.05, random_state=42)
gb_model.fit(X_train_gb, y_train_gb)

# Predict
y_train_gb_pred = gb_model.predict(X_train_gb)
y_test_gb_pred = gb_model.predict(X_test_gb)

# Evaluate
rmse_train_gb = np.sqrt(mean_squared_error(y_train_gb, y_train_gb_pred))
rmse_test_gb = np.sqrt(mean_squared_error(y_test_gb, y_test_gb_pred))
r2_train_gb = r2_score(y_train_gb, y_train_gb_pred)
r2_test_gb = r2_score(y_test_gb, y_test_gb_pred)

# Log
results.append({
    'Model': 'Gradient Boosting',
    'Train RMSE': rmse_train_gb,
    'Test RMSE': rmse_test_gb,
    'Train RÂ²': r2_train_gb,
    'Test RÂ²': r2_test_gb
})

results_df = pd.DataFrame(results)
display(results_df)

from sklearn.decomposition import PCA

# Ensure no NaNs
X_pca_fa = X_scaled.dropna()
y_pca_fa = y.loc[X_pca_fa.index]

# Create Lag_1_Return
df['Lag_1_Return'] = df['Next_Day_Return'].shift(1)
lag1 = df['Lag_1_Return'].loc[X_pca_fa.index]

# Apply PCA
pca = PCA(n_components=3)
pcs = pd.DataFrame(pca.fit_transform(X_pca_fa), index=X_pca_fa.index, columns=['PC1', 'PC2', 'PC3'])

# Combine Lag_1 + PCs
X_fa = pd.concat([lag1, pcs], axis=1).dropna()
y_fa = y_pca_fa.loc[X_fa.index]

# Split
X_train_fa = X_fa.loc[:'2022-12-31']
X_test_fa = X_fa.loc['2023-01-01':]
y_train_fa = y_fa.loc[:'2022-12-31']
y_test_fa = y_fa.loc['2023-01-01':]

# Fit OLS
X_train_fa_const = sm.add_constant(X_train_fa)
X_test_fa_const = sm.add_constant(X_test_fa)
fa_model = sm.OLS(y_train_fa, X_train_fa_const).fit()

# Predict
y_train_fa_pred = fa_model.predict(X_train_fa_const)
y_test_fa_pred = fa_model.predict(X_test_fa_const)

# Evaluate
rmse_train_fa = np.sqrt(mean_squared_error(y_train_fa, y_train_fa_pred))
rmse_test_fa = np.sqrt(mean_squared_error(y_test_fa, y_test_fa_pred))
r2_train_fa = r2_score(y_train_fa, y_train_fa_pred)
r2_test_fa = r2_score(y_test_fa, y_test_fa_pred)

# Log
results.append({
    'Model': 'Factor Augmentation (Lag1 + PCA)',
    'Train RMSE': rmse_train_fa,
    'Test RMSE': rmse_test_fa,
    'Train RÂ²': r2_train_fa,
    'Test RÂ²': r2_test_fa
})

results_df = pd.DataFrame(results)
display(results_df)

!pip install arch --quiet

from arch import arch_model

# Align and drop NA
returns = df['Next_Day_Return'].dropna()

# Train-test split
train_garch = returns.loc[:'2022-12-31']
test_garch = returns.loc['2023-01-01':]

# Fit GARCH(1,1)
garch_model = arch_model(train_garch, vol='Garch', p=1, q=1, rescale=False)
garch_result = garch_model.fit(disp='off')

# Forecast
forecast = garch_result.forecast(horizon=len(test_garch))
volatility_pred = np.sqrt(forecast.variance.values[-1])  # conditional volatility

# Dummy RMSE/RÂ² since GARCH doesn't predict return
results.append({
    'Model': 'GARCH(1,1)',
    'Train RMSE': np.nan,
    'Test RMSE': np.nan,
    'Train RÂ²': np.nan,
    'Test RÂ²': np.nan
})

results_df = pd.DataFrame(results)
display(results_df)

!pip install filterpy --quiet
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from filterpy.kalman import KalmanFilter
from filterpy.common import Q_discrete_white_noise

# Prep the data
df['Lag_1_Return'] = df['Next_Day_Return'].shift(1)
kf_df = df[['Next_Day_Return', 'Lag_1_Return']].dropna()

# Split into train/test
train_kf = kf_df.loc[:'2022-12-31']
test_kf = kf_df.loc['2023-01-01':]

Y_train = train_kf['Next_Day_Return'].values
X_train = train_kf['Lag_1_Return'].values

# Kalman filter setup: 1D state (beta), 1D measurement
kf = KalmanFilter(dim_x=1, dim_z=1)
kf.x = np.array([[0]])         # Initial beta estimate
kf.F = np.array([[1]])         # State transition matrix
kf.H = np.array([[1]])         # Observation matrix (X will be injected at each step)
kf.P *= 1                      # Initial covariance
kf.R *= 0.01                   # Measurement noise
kf.Q = np.array([[1e-5]])  # Replace Q_discrete_white_noise with manual 1D version


# Run the filter
predictions = []
estimated_betas = []

for t in range(len(Y_train)):
    kf.H = np.array([[X_train[t]]])  # Inject X_t as observation matrix
    kf.predict()
    kf.update(Y_train[t])
    pred = (kf.H @ kf.x)[0][0]
    predictions.append(pred)
    estimated_betas.append(kf.x[0][0])

# Evaluate
from sklearn.metrics import mean_squared_error, r2_score

rmse_kf = np.sqrt(mean_squared_error(Y_train, predictions))
r2_kf = r2_score(Y_train, predictions)

# Log results
results.append({
    'Model': 'Kalman Filter (Lag1)',
    'Train RMSE': rmse_kf,
    'Test RMSE': np.nan,     # only trained on train set here
    'Train RÂ²': r2_kf,
    'Test RÂ²': np.nan
})

results_df = pd.DataFrame(results)
display(results_df)

from sklearn.cross_decomposition import PLSRegression

# Drop missing
X_pls = X_scaled.dropna()
y_pls = y.loc[X_pls.index]

# Split
X_train_pls = X_pls.loc[:'2022-12-31']
X_test_pls = X_pls.loc['2023-01-01':]
y_train_pls = y_pls.loc[:'2022-12-31']
y_test_pls = y_pls.loc['2023-01-01':]

# Fit PLS with optimal components (try 2â€“5, here we choose 3)
pls = PLSRegression(n_components=3)
pls.fit(X_train_pls, y_train_pls)

# Predict
y_train_pls_pred = pls.predict(X_train_pls)
y_test_pls_pred = pls.predict(X_test_pls)

# Flatten predictions
y_train_pls_pred = y_train_pls_pred.ravel()
y_test_pls_pred = y_test_pls_pred.ravel()

# Evaluate
rmse_train_pls = np.sqrt(mean_squared_error(y_train_pls, y_train_pls_pred))
rmse_test_pls = np.sqrt(mean_squared_error(y_test_pls, y_test_pls_pred))
r2_train_pls = r2_score(y_train_pls, y_train_pls_pred)
r2_test_pls = r2_score(y_test_pls, y_test_pls_pred)

# Log
results.append({
    'Model': 'PLS Regression',
    'Train RMSE': rmse_train_pls,
    'Test RMSE': rmse_test_pls,
    'Train RÂ²': r2_train_pls,
    'Test RÂ²': r2_test_pls
})

results_df = pd.DataFrame(results)
display(results_df)

from sklearn.metrics import classification_report

# Use the best model predictions (e.g., ElasticNet or Random Forest)
# Assume: y_test = actual returns, y_test_pred = predicted returns (from best model)

threshold = 0.0015  # ~0.15% daily threshold

# Create predicted and actual labels
pred_signal = np.where(y_test_pred > threshold, 1,
                np.where(y_test_pred < -threshold, -1, 0))

actual_signal = np.where(y_test > threshold, 1,
                  np.where(y_test < -threshold, -1, 0))

from sklearn.metrics import classification_report, confusion_matrix

# Classification Report
print("ğŸ“‹ Classification Report (Buy/Hold/Sell):")
print(classification_report(actual_signal, pred_signal, target_names=['Sell (-1)', 'Hold (0)', 'Buy (+1)']))

# Optional: Confusion Matrix
conf_matrix = confusion_matrix(actual_signal, pred_signal, labels=[-1, 0, 1])
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Sell','Hold','Buy'], yticklabels=['Sell','Hold','Buy'])
plt.title("ğŸ“Š Confusion Matrix: Signal Classification")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

import matplotlib.pyplot as plt

# Convert results_df if needed
results_df = pd.DataFrame(results)

# Sort by test RÂ²
results_sorted = results_df.sort_values(by='Test RÂ²', ascending=False)

# Plot Test RÂ²
plt.figure(figsize=(12, 5))
sns.barplot(data=results_sorted, x='Model', y='Test RÂ²', palette='viridis')
plt.xticks(rotation=45, ha='right')
plt.title('ğŸ“ˆ Test RÂ² Comparison Across Models')
plt.ylabel('RÂ² (Out-of-sample)')
plt.tight_layout()
plt.show()

# Plot Test RMSE
plt.figure(figsize=(12, 5))
sns.barplot(data=results_sorted, x='Model', y='Test RMSE', palette='rocket')
plt.xticks(rotation=45, ha='right')
plt.title('ğŸ“‰ Test RMSE Comparison Across Models')
plt.ylabel('RMSE (Out-of-sample)')
plt.tight_layout()
plt.show()

import numpy as np

# Create DataFrame (if not already)
results_df = pd.DataFrame(results)

# Sort models alphabetically for consistent comparison
results_df_sorted = results_df.sort_values(by='Model')
models = results_df_sorted['Model'].values

# Set width for bars
bar_width = 0.35
x = np.arange(len(models))

# === RMSE Chart ===
plt.figure(figsize=(14, 6))
plt.bar(x - bar_width/2, results_df_sorted['Train RMSE'], bar_width, label='Train RMSE', color='steelblue')
plt.bar(x + bar_width/2, results_df_sorted['Test RMSE'], bar_width, label='Test RMSE', color='salmon')

plt.xticks(x, models, rotation=45, ha='right')
plt.ylabel('RMSE')
plt.title('ğŸ“‰ Train vs Test RMSE Comparison')
plt.legend()
plt.tight_layout()
plt.show()

# === RÂ² Chart ===
plt.figure(figsize=(14, 6))
plt.bar(x - bar_width/2, results_df_sorted['Train RÂ²'], bar_width, label='Train RÂ²', color='darkgreen')
plt.bar(x + bar_width/2, results_df_sorted['Test RÂ²'], bar_width, label='Test RÂ²', color='orange')

plt.xticks(x, models, rotation=45, ha='right')
plt.ylabel('RÂ²')
plt.title('ğŸ“ˆ Train vs Test RÂ² Comparison')
plt.legend()
plt.tight_layout()
plt.show()

"""TRADING SIGNAL"""

# Choose a reasonable return threshold (e.g., 0.0015 = 0.15%)
threshold = 0.0015

# Generate trading signal from predicted returns
predicted_signal = np.where(y_test_pred > threshold, 1,
                     np.where(y_test_pred < -threshold, -1, 0))

# Actual daily return
actual_return = y_test.values

# Compute strategy return
strategy_return = predicted_signal * actual_return

# Buy & Hold return (no signal, always long)
buy_hold_return = actual_return

# Create DataFrame to track
strategy_df = pd.DataFrame({
    'Predicted Signal': predicted_signal,
    'Actual Return': actual_return,
    'Strategy Return': strategy_return,
    'Buy & Hold Return': buy_hold_return
}, index=y_test.index)

# Compute cumulative returns
strategy_df['Cumulative Strategy'] = (1 + strategy_df['Strategy Return']).cumprod()
strategy_df['Cumulative BuyHold'] = (1 + strategy_df['Buy & Hold Return']).cumprod()

# Compute Sharpe Ratio
def sharpe_ratio(returns, risk_free_rate=0.0):
    excess_return = returns - risk_free_rate
    return np.sqrt(252) * excess_return.mean() / excess_return.std()

sharpe_strategy = sharpe_ratio(strategy_df['Strategy Return'])
sharpe_buyhold = sharpe_ratio(strategy_df['Buy & Hold Return'])

# Compute Max Drawdown
def max_drawdown(cumulative_returns):
    peak = cumulative_returns.cummax()
    drawdown = (cumulative_returns - peak) / peak
    return drawdown.min()

max_dd_strategy = max_drawdown(strategy_df['Cumulative Strategy'])
max_dd_buyhold = max_drawdown(strategy_df['Cumulative BuyHold'])

# Print results
print(f"ğŸ“ˆ Strategy Sharpe Ratio: {sharpe_strategy:.2f}")
print(f"ğŸ“‰ Max Drawdown: {max_dd_strategy:.2%}")
print(f"ğŸ†š Buy & Hold Sharpe: {sharpe_buyhold:.2f}, Drawdown: {max_dd_buyhold:.2%}")

plt.figure(figsize=(12, 5))
plt.plot(strategy_df['Cumulative Strategy'], label='Model Strategy')
plt.plot(strategy_df['Cumulative BuyHold'], label='Buy & Hold', linestyle='--')
plt.title("ğŸ“ˆ Cumulative Return Comparison")
plt.ylabel("Cumulative Return (Normalized)")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.linear_model import ElasticNetCV
from sklearn.model_selection import TimeSeriesSplit

# Simulate test set data (Replace with actual model output)
np.random.seed(42)
dates = pd.date_range(start='2023-01-01', periods=252, freq='B')
y_test = np.random.normal(0, 0.01, size=len(dates))
y_test_pred = y_test + np.random.normal(0, 0.005, size=len(dates))  # Simulate some signal

threshold = 0.0015

pred_signal = np.where(y_test_pred > threshold, 1,
                       np.where(y_test_pred < -threshold, -1, 0))
actual_signal = np.where(y_test > threshold, 1,
                         np.where(y_test < -threshold, -1, 0))

strategy_return = pred_signal * y_test
buy_hold_return = y_test

df = pd.DataFrame({
    'Strategy Return': strategy_return,
    'Buy & Hold Return': buy_hold_return
}, index=dates)

df['Cumulative Strategy'] = (1 + df['Strategy Return']).cumprod()
df['Cumulative BuyHold'] = (1 + df['Buy & Hold Return']).cumprod()

def sharpe_ratio(returns):
    return np.sqrt(252) * returns.mean() / returns.std()

def max_drawdown(cumulative_returns):
    peak = cumulative_returns.cummax()
    drawdown = (cumulative_returns - peak) / peak
    return drawdown.min()

print("Sharpe (Strategy):", sharpe_ratio(df['Strategy Return']))
print("Sharpe (Buy & Hold):", sharpe_ratio(df['Buy & Hold Return']))
print("Max Drawdown (Strategy):", max_drawdown(df['Cumulative Strategy']))
print("Max Drawdown (Buy & Hold):", max_drawdown(df['Cumulative BuyHold']))

print(classification_report(actual_signal, pred_signal, target_names=['Sell (-1)', 'Hold (0)', 'Buy (+1)']))

conf_matrix = confusion_matrix(actual_signal, pred_signal, labels=[-1, 0, 1])
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Sell', 'Hold', 'Buy'], yticklabels=['Sell', 'Hold', 'Buy'])
plt.title("ğŸ“Š Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

thresholds = np.arange(0.0005, 0.0035, 0.0005)
results = []

for th in thresholds:
    signal = np.where(y_test_pred > th, 1,
                      np.where(y_test_pred < -th, -1, 0))
    strat_return = signal * y_test
    cumulative = pd.Series((1 + strat_return).cumprod(), index=dates)

    sr = sharpe_ratio(strat_return)
    dd = max_drawdown(cumulative)
    acc = np.mean(np.sign(signal) == np.sign(y_test))

    results.append([th, sr, dd, acc])

threshold_df = pd.DataFrame(results, columns=['Threshold', 'Sharpe Ratio', 'Max Drawdown', 'Directional Accuracy'])

# Plot
plt.figure(figsize=(12, 5))
sns.lineplot(data=threshold_df, x='Threshold', y='Sharpe Ratio', marker='o', label='Sharpe')
sns.lineplot(data=threshold_df, x='Threshold', y='Directional Accuracy', marker='s', label='Accuracy')
plt.title("ğŸ“ˆ Threshold Tuning: Sharpe & Accuracy")
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()

# Simulate features (replace with real features in practice)
X = np.random.normal(0, 1, (300, 10))
y = np.random.normal(0, 0.01, size=300)

enet = ElasticNetCV(cv=TimeSeriesSplit(n_splits=5),
                    l1_ratio=[0.1, 0.5, 0.9],
                    alphas=np.logspace(-4, 0, 20),
                    max_iter=5000)
enet.fit(X, y)

print("Best Alpha:", enet.alpha_)
print("Best L1 Ratio:", enet.l1_ratio_)